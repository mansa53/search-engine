{"url": "https://www.reddit.com/r/learnprogramming/comments/9b01oj/a_server_can_handle_only_one_million_requests_how/", "text": "So that was my interview question so without vertical scaling how will you make the server handle 2 million requests?. So obviously I said horizontal scalability and that I will have a another similar server and in the web server apache or ngnix config, I would have the two IPs share the incoming requests so that it can take the load.\n\nThis was when the interviewer asked me an interesting question which I completely didn't think about. He asked me where will this webserver be located?\n\nI never thought about it. According to me it'd just be in one of the servers but the server can handle only 1 million requests how will it be handle this and pass it off to another server?\n\nI just went mute and didn't answer wondered how I didn't think about this one. Anyway in this case should I have just told them that when it means that the server can handle only 1 million requests it's talking about the application server and not the web server and that the web server can handle this and hand it off?\n\nSo should I say I should save the incoming requests in a message queue or something and handle it when it can?\n\nOr what is it? Can someone kindly enlighten me on this?", "score": 6, "comments": [{"body": "It's not very clear what's meant by \"1 million requests\". Assuming it means \"1 million requests per second\" then the next question is: are we bottlenecked by CPU or bandwidth? If the answer is CPU then you need another machine to host the 2nd webserver and you can distribute requests either by configuring the DNS server to do so or by adding a load balancer to your architecture. If it's bandwidth limited then adding a second machine within the same data center doesn't really help. ", "id": "e4zbj5q", "replies": [{"body": "Okay yeah should have asked him that so assuming it's CPU, the load balancing by done the web server is different so that's not what called the load balancer? It stays separately. ", "id": "e4zbxl1", "replies": [{"body": "I think we need to clarify some of the nomenclature: a load balancer is a piece of software that inspects a request's metadata and based on that dispatched the request to another server for processing. A web server is a piece of software that processes HTTP/S requests. You could run both on he same machine but that's counter productive if your web server is CPU limited. \n\nTo serve more requests from the same machine when limited by CPU you either need to optimize your web server to process requests faster (possible, but if you're using an off-the-shelf solution like NGINX you won't see 2x speed ups) or implement some additional caching that serves some requests without resorting to the web server (and not performing any calculations) like a key-value store. \n\nBoth the above probably won't net you 2x speedups. If you want 2x speedup you need to add 2x the hardware and serve the same webserver from both. Since clients access a webserver through a domain name, you can have the DNS server distribute users across the 2 machines (not guaranteed to give you a fair distribution of requests) or add a load balancer to distribute requests (more likely to distribute requests fairly). If the original machine did not possess enough compute for the web server then you will need a third machine for the load balancer. I hope this helps. ", "id": "e4zoc3v", "replies": []}]}]}, {"body": "Unpopular opinion: make the requests half as big by not bundling 100 copies of leftpad.", "id": "e4zzsoo", "replies": []}, {"body": "A million requests over what amount of time? If time doesn't matter, just let the CPU/network take double the time. \n\nIf it's in the same amount of time, more hardware would be the simplest solution. \n\nIf more hardware isn't an option, you could try doing some batching within the code to try and alleviate the server from being slammed all at once.", "id": "e4zessm", "replies": [{"body": "Is the proper way to use a load balancer and distribute the workload to several servers in a round robin fashion? If it requires a SQL backend, then add a master-slave pair?\n\nThough I'm not really sure what OP is asking", "id": "e4zh6ak", "replies": []}]}, {"body": "This is a bad interview question - It \\_may\\_ have been asked to see how you would cope with the task, basically thinking outside the specs given to you, (1M requests), and find a way to handle more requests - personally I would have said the following:\n\n* Implement a caching system (Assuming that we're serving HTML based content ... as in a web server)\n   * [https://www.nginx.com/blog/nginx-caching-guide/](https://www.nginx.com/blog/nginx-caching-guide/)\n   * [https://httpd.apache.org/docs/2.4/mod/mod\\_cache.html](https://httpd.apache.org/docs/2.4/mod/mod_cache.html)\n* Implement a CDN (Again - this is assuming HTML content and large images, and a well coded site)\n   * [https://aws.amazon.com/cloudfront/](https://aws.amazon.com/cloudfront/)\n   * [https://www.akamai.com/uk/en/cdn/](https://www.akamai.com/uk/en/cdn/)\n* Increase the bandwidth available to the server\n   * This can be good AND bad.\n      * Good - Networking configurations upstream could be intentionally throttled to prevent saturating the network, and 1M requests / sec / minute / hour whatever the measurement could be hampered by a max number of allowed connections\n      * Bad - The TCP/IP stack could fail with more bandwidth being made available to it the network interface could fail if it's hit with more data that it can process, which will just give a bad experience to all your clients/customers system making the requests\n* Add a second NIC to the Server - Channel Bond with the first nic\n   * [https://wiki.linuxfoundation.org/networking/bonding](https://wiki.linuxfoundation.org/networking/bonding)\n   * Take note about the TCP/IP stack possibly falling over\n\nThese are the things I can think of off the top of my head - I added some links to help you out, and also basically anyone else who comes across this thread - I hope my comments help you in the future", "id": "e506zk3", "replies": []}, {"body": "I would have drilled down and found out why it can only handle 1 million requests. I think the question was vague to test your ability to formulate probing questions to arrive at a more complete understanding. It's a communications question, not a problem solving question.", "id": "e50scj8", "replies": []}], "title": "A server can handle only one million requests, how will you make it handle 2 million requests without losing any of the requests?"}